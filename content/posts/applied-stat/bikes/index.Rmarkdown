---
title: "Excess rentals in TfL bike sharing"
date: 2022-09-13T17:00:20+00:00
description: Bike
author:
  name: Iris
  image: images/author/iris-cartoon.png
menu:
  sidebar:
    name: Excess rentals in bike sharing
    identifier: r-stat-bikes
    parent: R Statistics
    weight: 10
tags: ["R", "Data Analytics"]
categories: ["R"]
math: true
output: 
  toc: true
  html_document: 
# hero: images/hero.svg
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```

```{r load-libraries, include=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
library(wbstats)
library(countrycode)
library(patchwork)
library(gganimate)
library(infer)
library(GGally)
library(broom)
library(huxtable)
library(car)
library(performance)
library(ggfortify)
```

## 

Data: TfL data on how many bikes were hired every single day, from *London Data Store*

```{r, get_tfl_data, cache=TRUE}
url <- "https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx"

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp <- tempfile(fileext = ".xlsx")))

# Use read_excel to read it as dataframe
bike0 <- read_excel(bike.temp,
                   sheet = "Data",
                   range = cell_cols("A:B"))

# change dates to get year, month, and week
bike <- bike0 %>% 
  clean_names() %>% 
  rename (bikes_hired = number_of_bicycle_hires) %>% 
  mutate (year = year(day),
          month = lubridate::month(day, label = TRUE),
          week = isoweek(day))
```

```{r browse_data}
glimpse(bike)
skimr::skim(bike)
```

## Bikes hired by month and year since 2015

```{r tfl_month_year_grid}
bike %>% 
  filter(year >= 2015) %>% 
  ggplot(aes(x = bikes_hired)) + 
  geom_density() + 
  facet_grid(vars(year), vars(month)) + 
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank(), 
        axis.text.x = element_text(angle = 90, vjust = 1, hjust=1), 
        axis.text = element_text(size = 8)) + 
  scale_x_continuous(labels = scales::label_number(suffix = "K", scale = 0.001)) + 
  labs(x = "Bikes Hired", y = "", title = "Distribution of bikes hired per month")
```

## Monthly & Weekly Deviation from Expected Level

The code below creates a function to summary data with either `mean` or `median`, and then replicates graphs.

```{r function_get_exp_real}
get_values <- function(df, method, base_yr, target_yr) {
  # method = mean, or method = median
  # base_yr, e.g., c(2016, 2019)
  
  # summarize data by year & week
  by_week <- df %>% 
    filter(year >= target_yr[1] & year <= target_yr[2]) %>% 
    group_by(year, week) %>% 
    summarize(real = method(bikes_hired))
  
  # summarize data by year & month
  by_month <- df %>% 
  filter(year >= target_yr[1] & year <= target_yr[2]) %>% 
  group_by(year, month) %>% 
  summarize(real = method(bikes_hired))
  
  # weekly mean/median rentals across 2016~2019
  by_week_base <- df %>% 
    filter(year >= base_yr[1] & year <= base_yr[2]) %>% 
    group_by(week) %>% 
    summarize(expected = method(bikes_hired))
  
  # monthly mean/median rentals across 2016~2019
  by_month_base <- df %>% 
    filter(year >= base_yr[1] & year <= base_yr[2]) %>% 
    group_by(month) %>% 
    summarize(expected = method(bikes_hired))
  
  # joining real value and expected value, calculating excess amount and percentage changes
  gen_relative <- function(df1, df2, by_col){
    joined <- left_join(df1, df2, by = by_col) %>% 
      mutate(excess = real - expected, 
             perc = (real - expected) / expected)
    return(joined)
  }
  by_week <- gen_relative(by_week, by_week_base, "week") %>% 
    filter(!(year == 2022 & week == 52))
  by_month <- gen_relative(by_month, by_month_base, "month")

  # graph title - median or average
  if(method(c(1, 2, 3, 4, 5, 7)) == 3.5){  # if method() returns the median
    kwd <- "median"
  } else {kwd <- "average"}
  
  # graph1
  p1 <- by_month %>% 
  mutate(
    ymax = ifelse(real >= expected, real, expected), 
    ymin = ifelse(expected > real, real, expected)
  ) %>% 
  ggplot(aes(x = month)) +
    geom_line(aes(y = expected), group = 1, color = "blue", size = 1) + 
    geom_line(aes(y = real), group = 1, color = "black", size = 0.5) + 
    geom_ribbon(aes(ymin = expected, ymax = ymax, group = 1, fill="red"), 
                alpha = 0.5) + 
    geom_ribbon(aes(ymin = ymin, ymax = expected, group = 1, fill="green"), 
                alpha = 0.5) + 
    facet_wrap(~year) + 
    labs(
      title = "Monthly changes in TfL bike rentals", 
      subtitle = paste("Change from monthly ", kwd, " shown in blue and calculated between 2016-2019"), 
      caption = "Source: TfL, London Data Store", 
      y = paste("Bike Rentals (", kwd, ")"), 
      x = ""
    ) + 
    scale_y_continuous(labels = scales::label_number(suffix = "K", scale = 0.001)) + 
    theme(aspect.ratio = 0.6, 
          legend.position="none", 
          panel.background = element_rect(fill = "white"), 
          panel.grid = element_line(colour = "light grey"),
          strip.background = element_blank(), 
          axis.text.x = element_text(angle = 90, vjust = 1, hjust=1), 
          axis.text = element_text(size = 8), 
          axis.title = element_text(size = 8), 
          plot.title = element_text(size = 10)
          )
  
  # graph2
  yaxes_min <- min(by_week$perc)
  p2 <- by_week %>% 
    mutate(
      ymax = ifelse(perc >= 0, perc, 0), 
      ymin = ifelse(0 >= perc, perc, 0), 
      colors = ifelse(perc >= 0, "red", "green")
    ) %>% 
    ggplot() + 
    geom_line(aes(x = week, y = perc), group = 1, color = "black", size = 0.5) + 
    geom_ribbon(aes(x = week, ymin = ymin, ymax = 0, group = 1, fill="green"), 
                alpha = 0.5) + 
    geom_ribbon(aes(x = week, ymin = 0, ymax = ymax, group = 1, fill="red"), 
                alpha = 0.5) + 
    facet_wrap(~year) + 
    labs(
      title = "Weekly changes in TfL bike rentals", 
      subtitle = paste("% change from weekly", kwd, "calculated between 2016-2019"), 
      caption = "Source: TfL, London Data Store", 
      y = "", 
      x = "week"
    ) + 
    scale_y_continuous(labels = scales::percent, limits = c(yaxes_min, 1.1)) + 
    scale_x_discrete(limits=c(13, 26, 39, 53)) + 
    annotate(geom = "rect", xmin = 14, xmax = 26, ymin = -Inf, ymax = Inf, fill = "grey", alpha = 0.3) + 
    annotate(geom = "rect", xmin = 40, xmax = 53, ymin = -Inf, ymax = Inf, fill = "grey", alpha = 0.3) + 
    geom_rug(mapping = aes(x = week, color = factor(colors), alpha = 0.5), sides = "b") + 
    theme(aspect.ratio = 0.6, 
          legend.position="none", 
          panel.background = element_rect(fill = "white"), 
          panel.grid = element_line(colour = "light grey"), 
          strip.background = element_blank(), 
          axis.text = element_text(size = 8), 
          axis.title = element_text(size = 8), 
          plot.title = element_text(size = 10)
          )
  p1 / p2
}
```

Clarification 

- For the **"Monthly change from monthly average"** graph, 

    - The expected average or median monthly rentals are calculated using each month's records, regardless of year

-   For the **"Weekly change from weekly average"** graph,

    - The average or median weekly rentals are calculated using each week's records, regardless of year
    
    - The two grey shaded rectangles correspond to Q2 (weeks 14-26) and Q4 (weeks 40-52).

```{r result_bike_graph, out.width = "100%"}
get_values(bike, mean, c(2016, 2019), c(2017, 2022))
get_values(bike, median, c(2016, 2019), c(2017, 2022))
```

Although results using `mean` and `median` are similar, the average method is theoretically more suitable for evaluating expected rentals and %changes. Significant %changes are largely due to rentals surge on a few special days. The average value captures extremes while the median usually cannot. 

> Reference

-   <https://ggplot2.tidyverse.org/reference/geom_ribbon.html>
-   <https://ggplot2.tidyverse.org/reference/geom_tile.html>
-   <https://ggplot2.tidyverse.org/reference/geom_rug.html>

